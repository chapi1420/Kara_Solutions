{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleaner: A Python Class for Cleaning CSV Data  \n",
    "\n",
    "## Overview  \n",
    "The `DataCleaner` class provides a structured approach to cleaning and processing data stored in CSV files. It includes functionalities for handling missing values, standardizing text, extracting and removing emojis, managing YouTube links, and formatting the data for compatibility with PostgreSQL.\n",
    "\n",
    "## Features  \n",
    "- **Loading CSV files**  \n",
    "- **Handling missing values**  \n",
    "- **Extracting and removing emojis**  \n",
    "- **Extracting and removing YouTube links**  \n",
    "- **Standardizing text formatting**  \n",
    "- **Removing duplicates**  \n",
    "- **Ensuring PostgreSQL compatibility**  \n",
    "- **Saving cleaned data back to CSV**  \n",
    "- **Logging all actions for traceability**  \n",
    "\n",
    " Code Breakdown  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.cleaning import DataCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/nahomnadew/Desktop/10x/week7/Kara_Solutions/data/telegram_data2.csv'\n",
    "cleaned_data_path = '/home/nahomnadew/Desktop/10x/week7/Kara_Solutions/data/cleaned_telegram_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. **Class Initialization**  \n",
    "- Sets up logging to store messages in a file (`../logs/data_cleaning.log`) and display them in the console.\n",
    "- Ensures that the `logs` directory exists.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = DataCleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Loading CSV Data (`load_csv`)**  \n",
    "- Reads a CSV file into a Pandas DataFrame.\n",
    "- Logs success or failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:14:19,549 - INFO -  CSV file '/home/nahomnadew/Desktop/10x/week7/Kara_Solutions/data/telegram_data2.csv' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "df = clean.load_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Channel Title', 'Channel Username', 'ID', 'Message', 'Date',\n",
      "       'Media Path'],\n",
      "      dtype='object')\n",
      "                                       Channel Title Channel Username    ID  \\\n",
      "0  ETHIO-AMERICAN MEDICAL TRAININGS( CPD ) & HEAL...           @EAHCI  2603   \n",
      "1  ETHIO-AMERICAN MEDICAL TRAININGS( CPD ) & HEAL...           @EAHCI  2602   \n",
      "2  ETHIO-AMERICAN MEDICAL TRAININGS( CPD ) & HEAL...           @EAHCI  2601   \n",
      "3  ETHIO-AMERICAN MEDICAL TRAININGS( CPD ) & HEAL...           @EAHCI  2600   \n",
      "4  ETHIO-AMERICAN MEDICAL TRAININGS( CPD ) & HEAL...           @EAHCI  2598   \n",
      "\n",
      "                                             Message  \\\n",
      "0  #·ã®·åç·à≠·ãõ·âµ_·àµ·àç·å†·äì_·ãà·àã·ã≠·â≥_·à∂·ã∂\\n#Circumcision_Skill_Train...   \n",
      "1  #ENGLISH_LANGUAGE_TRAINING\\nüëâGrammar\\nüëâVocabul...   \n",
      "2  Congratulations to our beloved trainees on com...   \n",
      "3  #·ã®·åç·à≠·ãõ·âµ_·àµ·àç·å†·äì_Addis_Ababa \\n#Circumcision_Skill_...   \n",
      "4  ¬†#üí•CPD_·ä†·àÅ·äï_·ã≠·àò·ãù·åà·â° #·ã®·àû·ã´_·çà·âÉ·ãµ_·àà·àõ·à≥·ã∞·àµ_CPD_·ã≠·àò·ãù·åà·â°\\n#Ti...   \n",
      "\n",
      "                        Date  Media Path  \n",
      "0  2025-01-30 12:42:18+00:00         NaN  \n",
      "1  2025-01-30 12:17:14+00:00         NaN  \n",
      "2  2025-01-30 09:57:21+00:00         NaN  \n",
      "3  2025-01-29 17:00:02+00:00         NaN  \n",
      "4  2025-01-29 12:34:11+00:00         NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. **Emoji Handling**  \n",
    "- `extract_emojis(text)`: Extracts emojis from text, storing them in a new column.  \n",
    "- `remove_emojis(text)`: Removes emojis from text.  \n",
    "\n",
    "### 4. **YouTube Link Handling**  \n",
    "- `extract_youtube_links(text)`: Extracts YouTube links from text and stores them in a new column.  \n",
    "- `remove_youtube_links(text)`: Removes YouTube links from the message text.  \n",
    "\n",
    "### 5. **Text Cleaning (`clean_text`)**  \n",
    "- Replaces newline characters with spaces.\n",
    "- Ensures proper text formatting.\n",
    "\n",
    "### 6. **Data Cleaning (`clean_dataframe`)**  \n",
    "Performs multiple cleaning operations:\n",
    "- **Remove duplicates** based on the `ID` column.\n",
    "- **Convert date columns** to datetime format.\n",
    "- **Convert IDs** to integers (PostgreSQL `BIGINT` compatibility).\n",
    "- **Handle missing values** by filling with placeholders (`\"No Message\"`, `\"No Media\"`).\n",
    "- **Standardize text fields** (removing unnecessary spaces).\n",
    "- **Extract and remove emojis** from the `Message` column.\n",
    "- **Extract and remove YouTube links** from the `Message` column.\n",
    "- **Rename columns** to match PostgreSQL schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:14:19,598 - INFO -  Duplicates removed from dataset.\n",
      "2025-01-31 11:14:19,637 - INFO -  Date column formatted to datetime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahomnadew/Desktop/10x/week7/Kara_Solutions/scripts/cleaning.py:74: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['No Media' 'No Media' 'No Media' ... 'No Media' 'No Media' 'No Media']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'Media Path'] = df['Media Path'].fillna(\"No Media\")\n",
      "2025-01-31 11:14:19,645 - INFO -  Missing values filled.\n",
      "2025-01-31 11:14:19,685 - INFO -  Text columns standardized.\n",
      "2025-01-31 11:14:19,762 - INFO -  Emojis extracted and stored in 'emoji_used' column.\n",
      "2025-01-31 11:14:19,864 - INFO - YouTube links extracted and stored in 'youtube_links' column.\n",
      "2025-01-31 11:14:19,871 - INFO -  Data cleaning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "df2 = clean.clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. **Saving Cleaned Data (`save_cleaned_data`)**  \n",
    "- Saves the cleaned DataFrame to a new CSV file.  \n",
    "- Logs success or failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:14:30,587 - INFO -  Cleaned data saved successfully to '/home/nahomnadew/Desktop/10x/week7/Kara_Solutions/data/cleaned_telegram_data.csv'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned data saved successfully to '/home/nahomnadew/Desktop/10x/week7/Kara_Solutions/data/cleaned_telegram_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "clean.save_cleaned_data(df2, cleaned_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
